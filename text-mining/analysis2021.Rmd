---
title: "Analysis"
output: html_notebook
---
```{r setup, include=FALSE}
library(tidyverse)
library(tidytext)
library(stringr)
library(tm)
library(readxl)
library(wordcloud)
library(RColorBrewer)
library(topicmodels)
library(googlesheets4)
library(ldatuning)
library(ggplot2)
library(janitor)
library(readxl)


data = read_xlsx("./data/GPAI AIPR 2021 - Living Repository.xlsx", sheet = "Neda")

data = data %>% 
  filter(Status %in% c('Sent to evaluators', 'Information complete'))
```



# Preprocessing Data
```{r}
text_data = data %>% 
  mutate(initiative = row_number()) %>% 
  unite(text, Description:Mission, sep = " | ") %>% 
  select(initiative, text)

words = text_data %>% 
  unnest_tokens(word, text) 


custom_stopwords = c("covid","19","2","50")

words = words %>% 
  anti_join(stop_words) %>% 
  count(initiative, word, sort = TRUE) %>% 
  filter(!word %in% custom_stopwords ) 


words %>% 
  arrange(desc(n))
```


```{r}
words %>%
  filter(n > 3) %>% 
  arrange(n) %>% 
  mutate(word = fct_reorder(word, desc(n))) %>% 
  ggplot(aes(word, n)) +
  geom_bar(stat = "identity", fill = "#f68060", alpha = .6, width = .4) +
  coord_flip() +
  labs(y = NULL)
```

## LDA

### Generating Topics
```{r}
words_dtm = words %>% 
  cast_dtm(initiative, word, n)
```


```{r}

# Compute the K value "scores" from K=4 to K=45
result = FindTopicsNumber(
    words_dtm,
    topics = seq(from = 2, to = 25, by = 1),
    metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
    method = "Gibbs",
    control = list(seed = 1948),
    mc.cores = 2L,
    verbose = TRUE
)

FindTopicsNumber_plot(result)
```


```{r}
k = 8
topics = LDA(words_dtm,k = k)

word_topics = tidy(topics, matrix = "beta")

topic_terms = word_topics %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 10) %>% 
  ungroup() %>% 
  arrange(topic, -beta)

topic_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()

```


### Grouping projects by topics


```{r}
project_topics = tidy(topics, matrix = "gamma")
project_topics
```



## Saving to Google Sheets


### Word Connections
```{r}

filtered_words = word_topics %>% 
  filter(beta > 0.01) 

unique_words = unique(filtered_words$term)
topic_values = rep(NA, length(unique_words))
for (i in 1:length(topic_values)) {
  word = unique_words[i]
  values = filtered_words %>% 
    filter(term == word)
  values = values$topic
  values = str_c("Topic ", values)
  topics = str_c(values, collapse = "|")
  topic_values[[i]] = topics
}
word_rows = tibble(
  Label = unique_words, 
  Type = "Word",
  Topic = topic_values
  )

topic_labels = 1:k
topic_labels = str_c("Topic ", topic_labels)

topic_rows = tibble(
  Label = topic_labels,
  Type = "Topic",
  Topic = NA,
)

word_output = bind_rows(word_rows, topic_rows)

write_sheet(word_output, "https://docs.google.com/spreadsheets/d/1pNwt1-LH5ksxTPJJGO5wMFdjr7O14Bct5MvWm9uhUC8/edit#gid=0")

```


### Project Connections


```{r}
filtered_projects = project_topics %>% 
  filter(gamma > 0.01) %>% 
  mutate(Project = str_c("Project ", document)) %>% 
  select(Project, topic)

projects = str_c("Project ", 1:25)
topic_values = rep(NA, length(projects))
for (i in 1:length(projects)) {
  project = projects[i]
  values = filtered_projects %>% 
    filter(Project == project)
  values = values$topic
  values = str_c("Topic ", values)
  topics = str_c(values, collapse = "|")
  topic_values[[i]] = topics
}
project_rows = tibble(
  Label = projects, 
  Type = "Project",
  Topic = topic_values
  )

project_data = data %>% 
  mutate(Label = str_c("Project ", row_number())) %>% 
  select(Label, Description, Domain, Mission, Name) 
  

project_rows = left_join(project_rows, project_data, by = "Label")

project_rows = project_rows %>% 
  select(-Label) %>% 
  rename(Label = Name) %>% 
  select(Label, Type, Description, Topic, Domain, Mission)

project_output = bind_rows(project_rows, topic_rows)
write_sheet(project_output, "https://docs.google.com/spreadsheets/d/1p4QQaYk465-qHQmk-Wsh28dlk-z6iAkw6IJC4Dx1XFQ/edit#gid=0")

```


# Similarity Comparisons

```{r}
library(SnowballC)
library(stopwords)
library(text2vec)

tfidf_words = words %>% 
  select(-n) %>% 
  mutate(word = wordStem(word, language = "en")) %>% 
  count(initiative, word, sort = TRUE) %>% 
  bind_tf_idf(word, initiative, n)

sparse_matrix = tfidf_words %>% 
  cast_sparse(initiative, word, tf)


sparse_matrix[1:10, 1:4]
```

```{r}
similarities = sim2(sparse_matrix, method = "cosine", norm = "l2")
#similarities[1:10, 1:4]
as.matrix(similarities)
```

```{r}
library(reshape2)
melted_matrix =  melt(as.matrix(similarities))
```

```{r}

similarity_pairs = melted_matrix %>% 
  mutate(self_pair = map2_lgl(Var1, Var2, function(var1, var2) var1 == var2)) %>% 
  filter(self_pair == FALSE) %>% 
  select(-self_pair) %>% 
  rename(initiative1 = Var1, initiative2 = Var2) %>% 
  arrange(desc(value))

similarity_pairs
```



## Adding domain and categories

```{r}
catdoms = data %>% 
  select(Domain) %>% 
  mutate(initiative = row_number())

```

```{r}
similarity = similarity_pairs %>% 
  arrange(desc(value)) %>% 
  mutate(PrevP2 = lag(initiative1),PrevP1 = lag(initiative2),
         DuplicatedP1 = initiative1 == PrevP2,
         DuplicatedP2 = initiative2 == PrevP1,
         isDuplicated = DuplicatedP1 & DuplicatedP2,
         isDuplicated = replace_na(isDuplicated, FALSE)) %>% 
  filter(!isDuplicated) %>% 
  select(-PrevP2, -PrevP1, -DuplicatedP1, -DuplicatedP2, -isDuplicated)

```

```{r}
# in the new Live Repository we do not have category!
map_category_similarity = function(initiative1, initiative2) {
  Project1Cat = filter(catdoms, initiative == initiative1)$Category
  Project2Cat = filter(catdoms, initiative == initiative2)$Category
  
  return(as.numeric(Project1Cat == Project2Cat))
}

similarity = similarity %>% 
  mutate(CatSimilarity = map2_dbl(initiative1, initiative2, map_category_similarity))

```

```{r}
map_domain_similarity = function(initiative1, initiative2) {
  Project1Dom = filter(catdoms, initiative == initiative1)$Domain
  Project2Dom = filter(catdoms, initiative == initiative2)$Domain
  
  return(as.numeric(Project1Dom == Project2Dom))
}

similarity = similarity %>% 
  mutate(DomSimilarity = map2_dbl(initiative1, initiative2, map_domain_similarity))

```


```{r}
text_weight = 0.01
#cat_weight = 0.7
dom_weight = 0.29

similarity = similarity %>% 
  rowwise() %>% 
  mutate(Overall = value * text_weight + DomSimilarity * dom_weight) %>% 
  ungroup() %>% 
  arrange(desc(Overall))
similarity


```






